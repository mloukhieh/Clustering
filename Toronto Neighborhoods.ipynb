{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\eliec\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - folium=0.5.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    altair-4.1.0               |             py_1         614 KB  conda-forge\n",
      "    branca-0.4.2               |     pyhd8ed1ab_0          26 KB  conda-forge\n",
      "    conda-4.9.2                |   py38haa244fe_0         3.1 MB  conda-forge\n",
      "    folium-0.5.0               |             py_0          45 KB  conda-forge\n",
      "    openssl-1.1.1h             |       he774522_0         5.8 MB  conda-forge\n",
      "    python_abi-3.8             |           1_cp38           4 KB  conda-forge\n",
      "    vincent-0.4.4              |             py_1          28 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  altair             conda-forge/noarch::altair-4.1.0-py_1\n",
      "  branca             conda-forge/noarch::branca-0.4.2-pyhd8ed1ab_0\n",
      "  folium             conda-forge/noarch::folium-0.5.0-py_0\n",
      "  python_abi         conda-forge/win-64::python_abi-3.8-1_cp38\n",
      "  vincent            conda-forge/noarch::vincent-0.4.4-py_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda               pkgs/main::conda-4.9.2-py38haa95532_0 --> conda-forge::conda-4.9.2-py38haa244fe_0\n",
      "  openssl                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "folium-0.5.0         | 45 KB     |            |   0% \n",
      "folium-0.5.0         | 45 KB     | ###5       |  35% \n",
      "folium-0.5.0         | 45 KB     | ########## | 100% \n",
      "folium-0.5.0         | 45 KB     | ########## | 100% \n",
      "\n",
      "vincent-0.4.4        | 28 KB     |            |   0% \n",
      "vincent-0.4.4        | 28 KB     | ########## | 100% \n",
      "\n",
      "altair-4.1.0         | 614 KB    |            |   0% \n",
      "altair-4.1.0         | 614 KB    | 2          |   3% \n",
      "altair-4.1.0         | 614 KB    | ########## | 100% \n",
      "altair-4.1.0         | 614 KB    | ########## | 100% \n",
      "\n",
      "conda-4.9.2          | 3.1 MB    |            |   0% \n",
      "conda-4.9.2          | 3.1 MB    | 6          |   7% \n",
      "conda-4.9.2          | 3.1 MB    | ##3        |  24% \n",
      "conda-4.9.2          | 3.1 MB    | ####1      |  41% \n",
      "conda-4.9.2          | 3.1 MB    | #####8     |  59% \n",
      "conda-4.9.2          | 3.1 MB    | #######4   |  75% \n",
      "conda-4.9.2          | 3.1 MB    | #########1 |  92% \n",
      "conda-4.9.2          | 3.1 MB    | ########## | 100% \n",
      "\n",
      "branca-0.4.2         | 26 KB     |            |   0% \n",
      "branca-0.4.2         | 26 KB     | ########## | 100% \n",
      "\n",
      "python_abi-3.8       | 4 KB      |            |   0% \n",
      "python_abi-3.8       | 4 KB      | ########## | 100% \n",
      "\n",
      "openssl-1.1.1h       | 5.8 MB    |            |   0% \n",
      "openssl-1.1.1h       | 5.8 MB    |            |   0% \n",
      "openssl-1.1.1h       | 5.8 MB    | #1         |  12% \n",
      "openssl-1.1.1h       | 5.8 MB    | ##3        |  23% \n",
      "openssl-1.1.1h       | 5.8 MB    | ###5       |  35% \n",
      "openssl-1.1.1h       | 5.8 MB    | ####4      |  45% \n",
      "openssl-1.1.1h       | 5.8 MB    | #####6     |  57% \n",
      "openssl-1.1.1h       | 5.8 MB    | ######7    |  67% \n",
      "openssl-1.1.1h       | 5.8 MB    | #######7   |  77% \n",
      "openssl-1.1.1h       | 5.8 MB    | ########8  |  88% \n",
      "openssl-1.1.1h       | 5.8 MB    | #########9 |  99% \n",
      "openssl-1.1.1h       | 5.8 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Libraries Imported!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json \n",
    "\n",
    "#!conda install conda=4.6.14\n",
    "#!conda install -c conda-forge geopy --yes \n",
    "#!conda update --all --yes\n",
    "\n",
    "#from geopy.geocoders import Nominatim \n",
    "\n",
    "import requests \n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes \n",
    "import folium \n",
    "\n",
    "print(\"Libraries Imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Downloading data from Wikipedia and cleaning it to obtain the required Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the html data from wikipedia\n",
    "df = pd.read_html('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M')[0]\n",
    "\n",
    "# Delete rows where Borough is 'Not assigned'\n",
    "df = df[df.Borough!= \"Not assigned\"]\n",
    "\n",
    "# Combine all neighbourhoods that have the same postcode and Borough\n",
    "df = df.groupby(['Postal Code', 'Borough'])['Neighbourhood'].apply(list).apply(lambda x:', '.join(x)).to_frame().reset_index()\n",
    "\n",
    "# Replace by borough name when neighbourhood is not assigned\n",
    "for index, row in df.iterrows():\n",
    "    if row['Neighbourhood'] == 'Not assigned':\n",
    "        row['Neighbourhood'] = row['Borough']\n",
    "\n",
    "# define the dataframe columns\n",
    "column_names = ['Postcode','Borough', 'Neighborhood'] \n",
    "\n",
    "# create the dataframe\n",
    "df.columns = column_names\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Get the latitude and the longitude coordinates of each neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We are not able to get the geohraphical coordinates of the neighborhoods using the Geocoder package, we use the given csv file instead as suggested in the lab assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coor = pd.read_csv(\"http://cocl.us/Geospatial_data\")\n",
    "df_coor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine \"df\" and \"df_coor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coor.rename(columns={\"Postal Code\":\"Postcode\"}, inplace=True)\n",
    "\n",
    "df_toronto = pd.merge(df, df_coor)\n",
    "\n",
    "df_toronto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Explore and cluster the neighborhoods in Toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let's get the geographical coordinates of Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"Toronto, ON\"\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"toronto_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Toronto city are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's create a map of the whole Toronto City with neighborhoods superimposed on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of Toronto using latitude and longitude values\n",
    "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "map_toronto\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(\n",
    "        df_toronto['Latitude'], \n",
    "        df_toronto['Longitude'], \n",
    "        df_toronto['Borough'], \n",
    "        df_toronto['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto)  \n",
    "\n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring the boroughs that contain the word \"Toronto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toronto_ = df_toronto[df_toronto['Borough'].str.contains(\"Toronto\")].reset_index(drop=True)\n",
    "df_toronto_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the new Toronto map with boroughs containing the word \"Toronto\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_toronto_ = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "for lat, lng, borough, neighborhood in zip(\n",
    "        df_toronto_['Latitude'], \n",
    "        df_toronto_['Longitude'], \n",
    "        df_toronto_['Borough'], \n",
    "        df_toronto_['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto_)  \n",
    "\n",
    "map_toronto_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add Foursquare Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'IVDOAISHPYL3MC3OPERMAGK5JOMYWHJSOSSAOLMSJZORU0E2' # your Foursquare ID\n",
    "CLIENT_SECRET = 'ZBX2ZOLBXLFWZBKHEHCLHA3PXF4B5DIU5BFM1XQUQ5NJ5LHQ' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "LIMIT = 100 # A default Foursquare API limit value\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore the first neighborhood in our data frame \"df_toronto_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_name = df_toronto_.loc[0, 'Neighborhood']\n",
    "print(f\"The first neighborhood's name is '{neighborhood_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the neighborhoods coordinates\n",
    "neighborhood_latitude = df_toronto_.loc[0, 'Latitude'] # neighborhood latitude value\n",
    "neighborhood_longitude = df_toronto_.loc[0, 'Longitude'] # neighborhood longitude value\n",
    "\n",
    "print('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n",
    "                                                               neighborhood_latitude, \n",
    "                                                               neighborhood_longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the top 100 venues that are in The Beaches within a radius of 500 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "radius = 500 # define radius\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    neighborhood_latitude, \n",
    "    neighborhood_longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "\n",
    "# get the result to a json file\n",
    "results = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts the category of the venue\n",
    "\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the json and structure it into a pandas dataframe\n",
    "\n",
    "venues = results['response']['groups'][0]['items']\n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring the neighborhoods that contain the word \"Toronto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to repeat the same process to all the neighborhoods in df_Toronto_ just like we did with \"the beaches\"\n",
    "\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    venues_list=[]\n",
    "    \n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        # print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the above function on each neighborhood and create a new dataframe called toronto_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues = getNearbyVenues(names=df_toronto_['Neighborhood'],\n",
    "                                   latitudes=df_toronto_['Latitude'],\n",
    "                                   longitudes=df_toronto_['Longitude']\n",
    "                                  )\n",
    "\n",
    "toronto_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysing the neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out how many unique venues\n",
    "print('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "toronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\n",
    "toronto_onehot = toronto_onehot[fixed_columns]\n",
    "\n",
    "toronto_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "toronto_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### print each neighborhood along with the top 5 most common venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in toronto_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = toronto_grouped[toronto_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Put that into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's write a function to sort the venues in descending order\n",
    "\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create the new dataframe and display the top 10 venues for each neighborhood\n",
    "\n",
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(toronto_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering the neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Due to the small number of neighborhoods and their proximity we will be clustering them into 2 clusters only using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 2\n",
    "\n",
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "toronto_merged = df_toronto_\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "toronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "toronto_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's visualize the resulting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(\n",
    "        toronto_merged['Latitude'], \n",
    "        toronto_merged['Longitude'], \n",
    "        toronto_merged['Neighborhood'], \n",
    "        toronto_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "##### it seems that Cluster \"0\" has a lot of cafes, restaurants, bars and Hotels whereas Cluster \"1\" has more parks, playgrounds, dog runs and trails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
